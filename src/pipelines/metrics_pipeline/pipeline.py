"""Metrics Pipeline implementation - Stage 3 of Tetra data processing."""

import asyncio
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime, date
import pandas as pd
import numpy as np
import json
from concurrent.futures import ProcessPoolExecutor, as_completed
import pyarrow as pa
import pyarrow.parquet as pq

from src.pipelines.base import PipelineContext, PipelineStatus
from src.pipelines.scenarios_pipeline.steps.scenario_storage import ScenarioLoaderStep
from src.pipelines.metrics_pipeline.calculators.technical import TechnicalCalculator
from src.pipelines.metrics_pipeline.calculators.statistical import StatisticalCalculator
from src.simulators.utils.data_loader import DataLoader
import logging

logger = logging.getLogger(__name__)


class MetricsPipeline:
    """
    Metrics Pipeline - Pre-calculates all technical indicators and statistical metrics
    for each scenario generated by the Scenarios Pipeline.
    
    This is Stage 3 of the 4-stage pipeline architecture:
    1. Data Pipeline → 2. Scenarios Pipeline → 3. Metrics Pipeline → 4. Assessment Pipeline
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """Initialize the Metrics Pipeline."""
        self.name = "MetricsPipeline"
        self.config = config or {}
        
        # Configuration
        self.parallel_workers = self.config.get('parallel_workers', 8)
        self.batch_size = self.config.get('batch_size', 50)
        self.storage_dir = Path(self.config.get('storage_dir', 'data/metrics'))
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
        # Data loader for market data
        self.data_loader = DataLoader()
        
        # Calculators
        self.technical_calculator = TechnicalCalculator()
        self.statistical_calculator = StatisticalCalculator()
        
        # Add event metrics calculator
        from src.pipelines.metrics_pipeline.calculators.event_metrics import EventMetricsCalculator
        self.event_calculator = EventMetricsCalculator()
        
        # Add ML metrics calculator
        from src.pipelines.metrics_pipeline.calculators.ml_metrics import MLMetricsCalculator
        self.ml_calculator = MLMetricsCalculator()
        
        # Cache for market data
        self.market_data_cache = {}
        
    async def run(self, 
                  scenario_filter: Optional[str] = None,
                  symbols_filter: Optional[List[str]] = None,
                  force_recalculate: bool = False) -> Dict[str, Any]:
        """
        Run the metrics pipeline.
        
        Args:
            scenario_filter: Optional filter for specific scenario types
            symbols_filter: Optional list of symbols to process
            force_recalculate: Force recalculation even if metrics exist
            
        Returns:
            Dictionary with pipeline results
        """
        start_time = datetime.now()
        logger.info("Starting Metrics Pipeline execution")
        
        try:
            # Step 1: Load scenarios from Scenarios Pipeline output
            logger.info("Loading scenarios...")
            scenarios = await self._load_scenarios(scenario_filter)
            logger.info(f"Loaded {len(scenarios)} scenarios")
            
            # Step 2: Get unique symbols across all scenarios
            symbols = self._get_unique_symbols(scenarios, symbols_filter)
            logger.info(f"Processing {len(symbols)} unique symbols")
            
            # Step 3: Load market data for all symbols
            logger.info("Loading market data...")
            await self._load_market_data(symbols)
            
            # Step 4: Process scenarios in parallel
            logger.info("Calculating metrics for all scenarios...")
            results = await self._process_scenarios_parallel(
                scenarios, 
                force_recalculate
            )
            
            # Step 5: Save summary
            summary = self._create_summary(results, start_time)
            self._save_summary(summary)
            
            logger.info(f"Metrics Pipeline completed in {summary['execution_time']}")
            return summary
            
        except Exception as e:
            logger.error(f"Metrics Pipeline failed: {e}")
            raise
    
    async def _load_scenarios(self, scenario_filter: Optional[str] = None) -> List[Dict]:
        """Load scenarios from the Scenarios Pipeline output."""
        loader = ScenarioLoaderStep()
        context = PipelineContext()
        context = await loader.execute(context)
        scenarios = context.data.get('scenarios', [])
        
        if scenario_filter:
            # Filter scenarios by type if specified
            filtered = [s for s in scenarios if scenario_filter.lower() in s.get('scenario_type', '').lower()]
            return filtered
        
        return scenarios
    
    def _get_unique_symbols(self, scenarios: List[Dict], symbols_filter: Optional[List[str]] = None) -> List[str]:
        """Get unique symbols across all scenarios."""
        from src.definitions.market_universe import MarketUniverse
        
        symbols = set()
        
        for scenario in scenarios:
            # Add symbols from scenario metadata
            scenario_symbols = scenario.get('symbols', [])
            if not scenario_symbols:
                # Use ALL symbols if none specified
                scenario_symbols = MarketUniverse.get_all_symbols()
            symbols.update(scenario_symbols)
        
        # Apply filter if provided
        if symbols_filter:
            symbols = symbols.intersection(set(symbols_filter))
        
        return sorted(list(symbols))
    
    async def _load_market_data(self, symbols: List[str]) -> None:
        """Load market data for all symbols from database."""
        from src.definitions.trading import TradingConstants
        from datetime import date, timedelta
        import asyncio
        
        # Get all available data from database (last 2 years for efficiency)
        end_date = date.today()
        start_date = end_date - timedelta(days=730)  # 2 years
        
        # Add benchmark to symbols if not present
        benchmark = TradingConstants.DEFAULT_BENCHMARK
        all_symbols = list(set(symbols + [benchmark]))
        
        try:
            # Load all symbols in batch from database with timeout
            logger.info(f"Loading market data for {len(all_symbols)} symbols...")
            
            # Add timeout to prevent hanging
            batch_data = await asyncio.wait_for(
                self.data_loader.load_ohlcv_batch(
                    symbols=all_symbols,
                    start_date=start_date,
                    end_date=end_date
                ),
                timeout=30.0  # 30 second timeout
            )
            
            # Update cache
            self.market_data_cache.update(batch_data)
            logger.info(f"Successfully loaded data for {len(batch_data)} symbols")
            
            # Mark missing symbols as None
            for symbol in all_symbols:
                if symbol not in self.market_data_cache:
                    logger.warning(f"No data found for {symbol} in database")
                    self.market_data_cache[symbol] = None
                    
        except asyncio.TimeoutError:
            logger.error("Database loading timed out after 30 seconds - using empty cache")
            # Mark all symbols as None if database times out
            for symbol in all_symbols:
                self.market_data_cache[symbol] = None
        except Exception as e:
            logger.error(f"Failed to load market data batch: {e}")
            # Try loading individually as fallback
            for symbol in all_symbols:
                if symbol not in self.market_data_cache:
                    self.market_data_cache[symbol] = None
    
    async def _process_scenarios_parallel(self, 
                                         scenarios: List[Dict],
                                         force_recalculate: bool) -> List[Dict]:
        """Process scenarios in parallel."""
        results = []
        
        # Create batches for parallel processing
        batches = [scenarios[i:i + self.batch_size] 
                  for i in range(0, len(scenarios), self.batch_size)]
        
        with ProcessPoolExecutor(max_workers=self.parallel_workers) as executor:
            # Submit batch processing tasks
            futures = []
            for batch in batches:
                future = executor.submit(
                    self._process_scenario_batch,
                    batch,
                    self.market_data_cache,
                    force_recalculate
                )
                futures.append(future)
            
            # Collect results
            for future in as_completed(futures):
                try:
                    batch_results = future.result()
                    results.extend(batch_results)
                except Exception as e:
                    logger.error(f"Batch processing failed: {e}")
        
        return results
    
    @staticmethod
    def _process_scenario_batch(scenarios: List[Dict],
                               market_data_cache: Dict[str, pd.DataFrame],
                               force_recalculate: bool) -> List[Dict]:
        """Process a batch of scenarios (runs in subprocess)."""
        results = []
        
        for scenario in scenarios:
            try:
                # Check if metrics already exist
                scenario_name = scenario.get('name', 'unknown')
                
                
                metrics_file = Path(f"data/metrics/{scenario_name}_metrics.parquet")
                
                if metrics_file.exists() and not force_recalculate:
                    logger.info(f"Metrics already exist for {scenario_name}, skipping...")
                    results.append({
                        'scenario': scenario_name,
                        'status': 'skipped',
                        'file': str(metrics_file)
                    })
                    continue
                
                # Calculate metrics for this scenario
                scenario_metrics = MetricsPipeline._calculate_scenario_metrics(
                    scenario,
                    market_data_cache
                )
                
                # Save metrics
                MetricsPipeline._save_scenario_metrics(scenario_name, scenario_metrics)
                
                results.append({
                    'scenario': scenario_name,
                    'status': 'completed',
                    'metrics_count': len(scenario_metrics),
                    'file': str(metrics_file)
                })
                
            except Exception as e:
                logger.error(f"Failed to process scenario {scenario.get('name')}: {e}")
                results.append({
                    'scenario': scenario.get('name', 'unknown'),
                    'status': 'failed',
                    'error': str(e)
                })
        
        return results
    
    @staticmethod
    def _calculate_scenario_metrics(scenario: Dict,
                                   market_data_cache: Dict[str, pd.DataFrame]) -> pd.DataFrame:
        """Calculate all metrics for a scenario."""
        all_metrics = []
        
        from src.definitions.trading import TradingConstants
        from src.definitions.market_universe import MarketUniverse
        
        # Get scenario parameters - ensure timezone-naive for comparison
        start_date = pd.to_datetime(scenario.get('start_date'))
        end_date = pd.to_datetime(scenario.get('end_date'))
        # Remove timezone info if present
        if start_date.tz is not None:
            start_date = start_date.tz_localize(None)
        if end_date.tz is not None:
            end_date = end_date.tz_localize(None)
        
        # Check if scenario has simulated data
        scenario_data_dict = scenario.get('data', {})
        
        # Get symbols from scenario data or use defaults
        if scenario_data_dict:
            symbols = list(scenario_data_dict.keys())
        else:
            symbols = scenario.get('symbols', [])
            if not symbols:
                symbols = MarketUniverse.get_all_symbols()
        
        # Get benchmark data for market correlation
        benchmark = TradingConstants.DEFAULT_BENCHMARK
        benchmark_data = market_data_cache.get(benchmark)
        
        for symbol in symbols:
            # Use scenario's simulated data if available, otherwise use market data
            if symbol in scenario_data_dict and scenario_data_dict[symbol]:
                # Convert scenario data to DataFrame
                scenario_timeseries = scenario_data_dict[symbol]
                if isinstance(scenario_timeseries, list) and scenario_timeseries:
                    scenario_data = pd.DataFrame(scenario_timeseries)
                    # Ensure timestamp is datetime index
                    if 'timestamp' in scenario_data.columns:
                        scenario_data['timestamp'] = pd.to_datetime(scenario_data['timestamp'])
                        scenario_data.set_index('timestamp', inplace=True)
                    elif 'date' in scenario_data.columns:
                        scenario_data['date'] = pd.to_datetime(scenario_data['date'])
                        scenario_data.set_index('date', inplace=True)
                else:
                    # Fall back to market data
                    data = market_data_cache.get(symbol)
                    if data is None or data.empty:
                        continue
                    # Ensure index is timezone-naive for comparison
                    data_index = data.index
                    if hasattr(data_index, 'tz') and data_index.tz is not None:
                        data_index = data_index.tz_localize(None)
                    mask = (data_index >= start_date) & (data_index <= end_date)
                    scenario_data = data.loc[mask].copy()
            else:
                # Use market data for this symbol
                data = market_data_cache.get(symbol)
                if data is None or data.empty:
                    continue
                
                # Filter to scenario date range - ensure timezone-naive comparison
                data_index = data.index
                if hasattr(data_index, 'tz') and data_index.tz is not None:
                    data_index = data_index.tz_localize(None)
                mask = (data_index >= start_date) & (data_index <= end_date)
                scenario_data = data.loc[mask].copy()
            
            if scenario_data.empty:
                continue
            
            # Remove any duplicate index values before processing
            if scenario_data.index.duplicated().any():
                scenario_data = scenario_data[~scenario_data.index.duplicated(keep='first')]
            
            # Calculate ALL technical indicators with error handling
            try:
                technical_metrics = TechnicalCalculator.calculate_all(scenario_data)
            except Exception as e:
                logger.warning(f"Technical indicators failed for {symbol}: {e}")
                technical_metrics = {}
            
            # Calculate ALL statistical metrics with error handling
            # Get benchmark data for the same period if available
            benchmark_subset = None
            if benchmark_data is not None and not benchmark_data.empty:
                try:
                    # Match the date range of scenario_data
                    if hasattr(scenario_data.index, 'min') and hasattr(scenario_data.index, 'max'):
                        bmask = (benchmark_data.index >= scenario_data.index.min()) & (benchmark_data.index <= scenario_data.index.max())
                        benchmark_subset = benchmark_data.loc[bmask]
                except Exception:
                    # If we can't subset, just pass None
                    benchmark_subset = None
            
            try:        
                statistical_metrics = StatisticalCalculator.calculate_all(
                    scenario_data,
                    benchmark_subset
                )
            except Exception as e:
                logger.warning(f"Statistical metrics failed for {symbol}: {e}")
                statistical_metrics = {}
            
            # Calculate event metrics with error handling
            try:
                from src.pipelines.metrics_pipeline.calculators.event_metrics import EventMetricsCalculator
                event_calculator = EventMetricsCalculator()
                event_metrics = event_calculator.calculate_event_metrics(scenario_data, symbol)
            except Exception as e:
                logger.warning(f"Event metrics failed for {symbol}: {e}")
                event_metrics = pd.DataFrame()
            
            # Calculate ML metrics - TEMPORARILY DISABLED DUE TO LENGTH ISSUES
            # from src.pipelines.metrics_pipeline.calculators.ml_metrics import MLMetricsCalculator
            # ml_calculator = MLMetricsCalculator()
            # # Pass data with technical indicators already calculated
            # # Build data_with_indicators without duplicates
            # data_with_indicators = scenario_data.copy()
            # tech_df = pd.DataFrame(technical_metrics)
            # stat_df = pd.DataFrame(statistical_metrics)
            # for col in tech_df.columns:
            #     if col not in data_with_indicators.columns:
            #         data_with_indicators[col] = tech_df[col]
            # for col in stat_df.columns:
            #     if col not in data_with_indicators.columns:
            #         data_with_indicators[col] = stat_df[col]
            # ml_metrics = ml_calculator.calculate_ml_metrics(data_with_indicators, symbol)
            ml_metrics = pd.DataFrame()  # Empty for now
            
            # Combine all metrics - more efficient approach using concat
            # Remove any duplicate index values first
            if scenario_data.index.duplicated().any():
                scenario_data = scenario_data[~scenario_data.index.duplicated(keep='first')]
            
            # Collect all DataFrames to concatenate
            dfs_to_concat = [scenario_data.copy()]
            
            # Add technical metrics
            if technical_metrics:
                try:
                    metrics_df = pd.DataFrame(technical_metrics)
                    if not metrics_df.empty:
                        metrics_df = metrics_df.reindex(scenario_data.index)
                        # Remove columns that already exist in scenario_data
                        metrics_df = metrics_df[[col for col in metrics_df.columns if col not in scenario_data.columns]]
                        if not metrics_df.empty:
                            dfs_to_concat.append(metrics_df)
                except Exception as e:
                    logger.warning(f"Failed to prepare technical metrics: {e}")
            
            # Add statistical metrics
            if statistical_metrics:
                try:
                    stats_df = pd.DataFrame(statistical_metrics)
                    if not stats_df.empty:
                        stats_df = stats_df.reindex(scenario_data.index)
                        # Remove columns that already exist
                        existing_cols = set()
                        for df in dfs_to_concat:
                            existing_cols.update(df.columns)
                        stats_df = stats_df[[col for col in stats_df.columns if col not in existing_cols]]
                        if not stats_df.empty:
                            dfs_to_concat.append(stats_df)
                except Exception as e:
                    logger.warning(f"Failed to prepare statistical metrics: {e}")
            
            # Add event metrics if available
            if isinstance(event_metrics, pd.DataFrame) and not event_metrics.empty:
                event_metrics = event_metrics.reindex(scenario_data.index)
                existing_cols = set()
                for df in dfs_to_concat:
                    existing_cols.update(df.columns)
                event_metrics = event_metrics[[col for col in event_metrics.columns if col not in existing_cols]]
                if not event_metrics.empty:
                    dfs_to_concat.append(event_metrics)
            
            # Add ML metrics if available
            if isinstance(ml_metrics, pd.DataFrame) and not ml_metrics.empty:
                ml_metrics = ml_metrics.reindex(scenario_data.index)
                existing_cols = set()
                for df in dfs_to_concat:
                    existing_cols.update(df.columns)
                ml_metrics = ml_metrics[[col for col in ml_metrics.columns if col not in existing_cols]]
                if not ml_metrics.empty:
                    dfs_to_concat.append(ml_metrics)
            
            # Concatenate all DataFrames at once to avoid fragmentation
            combined = pd.concat(dfs_to_concat, axis=1)
            combined['symbol'] = symbol
            combined['scenario'] = scenario.get('name', 'unknown')
            
            all_metrics.append(combined)
        
        # Combine all symbols - ensure consistent structure
        if all_metrics:
            # Ensure all DataFrames have the same columns by finding union of all columns
            all_columns = set()
            for df in all_metrics:
                all_columns.update(df.columns)
            
            # Reindex all DataFrames to have the same columns
            aligned_metrics = []
            for df in all_metrics:
                aligned_df = df.reindex(columns=list(all_columns))
                aligned_metrics.append(aligned_df)
            
            return pd.concat(aligned_metrics, ignore_index=False)
        else:
            return pd.DataFrame()
    
    @staticmethod
    def _save_scenario_metrics(scenario_name: str, metrics: pd.DataFrame) -> None:
        """Save metrics for a scenario."""
        if metrics.empty:
            return
        
        storage_dir = Path('data/metrics')
        storage_dir.mkdir(parents=True, exist_ok=True)
        
        # Save as parquet for efficient storage
        output_file = storage_dir / f"{scenario_name}_metrics.parquet"
        
        # Convert to pyarrow table and save
        table = pa.Table.from_pandas(metrics)
        pq.write_table(table, output_file, compression='snappy')
        
        logger.info(f"Saved metrics for {scenario_name} to {output_file}")
    
    def _create_summary(self, results: List[Dict], start_time: datetime) -> Dict[str, Any]:
        """Create pipeline execution summary."""
        end_time = datetime.now()
        execution_time = (end_time - start_time).total_seconds()
        
        completed = [r for r in results if r.get('status') == 'completed']
        failed = [r for r in results if r.get('status') == 'failed']
        skipped = [r for r in results if r.get('status') == 'skipped']
        
        summary = {
            'pipeline': 'MetricsPipeline',
            'execution_date': start_time.isoformat(),
            'execution_time': f"{execution_time:.2f} seconds",
            'total_scenarios': len(results),
            'completed': len(completed),
            'failed': len(failed),
            'skipped': len(skipped),
            'storage_location': str(self.storage_dir),
            'results': results
        }
        
        return summary
    
    def _save_summary(self, summary: Dict[str, Any]) -> None:
        """Save execution summary."""
        summary_file = self.storage_dir / 'metrics_pipeline_summary.json'
        
        with open(summary_file, 'w') as f:
            json.dump(summary, f, indent=2, default=str)
        
        logger.info(f"Saved pipeline summary to {summary_file}")