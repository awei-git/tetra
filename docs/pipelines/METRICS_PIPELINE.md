# Metrics Pipeline Documentation

> **Implementation Status**: ✅ IMPLEMENTED (Stage 3 of 4-stage pipeline architecture)
> 
> This pipeline runs daily at 8:00 PM after the Scenarios Pipeline completes.

## Overview

The Metrics Pipeline is Stage 3 of the Tetra platform's data processing architecture. It pre-calculates all technical indicators, statistical metrics, and machine learning features for each of the 131 scenarios generated by the Scenarios Pipeline. By computing these metrics once and storing them, the pipeline eliminates redundant calculations during strategy backtesting, dramatically improving performance and ensuring consistency.

## Purpose

- **Pre-calculate all derived metrics** to avoid redundant computation
- **Ensure consistency** by using the same calculations across all strategies
- **Enable fast backtesting** through cached metric access
- **Support complex indicators** that would be expensive to compute repeatedly
- **Provide scenario-specific metrics** adjusted for each market environment

## Architecture

### Pipeline Structure (IMPLEMENTED)
```
src/pipelines/
├── metrics_pipeline/
│   ├── __init__.py             # ✅ Package initialization
│   ├── pipeline.py             # ✅ MetricsPipeline implementation
│   ├── main.py                 # ✅ CLI entry point
│   └── calculators/            # ✅ Metric calculation modules
│       ├── technical.py        # ✅ 70+ technical indicators
│       └── statistical.py      # ✅ 50+ statistical metrics
```

### Execution Schedule
```
7:00 PM - Data Pipeline (Stage 1)
7:30 PM - Scenarios Pipeline (Stage 2)
8:00 PM - Metrics Pipeline (Stage 3) ← Runs automatically
```

### Integration with Signals Module
```
src/signals/                    # Existing signals module
├── technical/                  # Leveraged by metrics pipeline
│   ├── trend.py               # SMA, EMA, MACD, etc.
│   ├── momentum.py            # RSI, Stochastic, CCI
│   ├── volatility.py          # Bollinger Bands, ATR, Keltner
│   └── volume.py              # OBV, Volume Profile, VWAP
├── statistical/
│   ├── returns.py             # Return calculations
│   └── volatility.py          # Volatility metrics
└── ml/
    ├── features.py            # Feature engineering
    └── predictions.py         # ML model predictions
```

## Metric Categories

### 1. Technical Indicators

Over 200 technical indicators organized by category:

#### Trend Indicators
```python
TREND_INDICATORS = {
    # Moving Averages
    "sma": [5, 10, 20, 50, 100, 200],
    "ema": [12, 26, 50, 200],
    "wma": [10, 20, 50],
    "dema": [20, 50],
    "tema": [20, 50],
    "kama": [10, 30],  # Kaufman Adaptive MA
    
    # Trend Strength
    "adx": [14],  # Average Directional Index
    "aroon": [25],  # Aroon Up/Down
    "psar": [],  # Parabolic SAR
    "supertrend": [10, 3],  # Period, Multiplier
    
    # Channels
    "keltner": [20, 2],  # Period, ATR Multiplier
    "donchian": [20],  # Donchian Channels
}
```

#### Momentum Indicators
```python
MOMENTUM_INDICATORS = {
    "rsi": [14, 21],  # Relative Strength Index
    "stochastic": [14, 3],  # %K, %D
    "macd": [12, 26, 9],  # Fast, Slow, Signal
    "cci": [20],  # Commodity Channel Index
    "williams_r": [14],  # Williams %R
    "roc": [10, 20],  # Rate of Change
    "tsi": [25, 13],  # True Strength Index
    "ultimate": [7, 14, 28],  # Ultimate Oscillator
}
```

#### Volatility Indicators
```python
VOLATILITY_INDICATORS = {
    "bollinger": [20, 2],  # Period, Std Dev
    "atr": [14],  # Average True Range
    "natr": [14],  # Normalized ATR
    "chandelier": [22, 3],  # Period, ATR Multiplier
    "historical_volatility": [20, 252],  # Period, Annualization
    "garman_klass": [20],  # Garman-Klass Volatility
    "parkinson": [20],  # Parkinson Volatility
}
```

#### Volume Indicators
```python
VOLUME_INDICATORS = {
    "obv": [],  # On-Balance Volume
    "cmf": [20],  # Chaikin Money Flow
    "mfi": [14],  # Money Flow Index
    "vwap": [],  # Volume-Weighted Average Price
    "volume_profile": [50],  # Number of bins
    "accumulation_distribution": [],
    "ease_of_movement": [14],
}
```

### 2. Statistical Metrics

Advanced statistical calculations:

```python
STATISTICAL_METRICS = {
    # Returns
    "returns": {
        "simple": [1, 5, 20, 60],  # Daily, Weekly, Monthly, Quarterly
        "log": [1, 5, 20, 60],
        "excess": [1, 5, 20],  # Over risk-free rate
    },
    
    # Volatility
    "volatility": {
        "realized": [20, 60, 252],
        "garch": [1, 1],  # GARCH(1,1) forecast
        "ewma": [0.94],  # Exponential weighted
        "yang_zhang": [20],  # Yang-Zhang estimator
    },
    
    # Risk Metrics
    "risk": {
        "var": [0.95, 0.99],  # Value at Risk
        "cvar": [0.95, 0.99],  # Conditional VaR
        "max_drawdown": [252],  # Rolling max drawdown
        "downside_deviation": [252],
        "semi_variance": [252],
    },
    
    # Correlation
    "correlation": {
        "rolling": [20, 60, 252],  # With market index
        "dynamic": ["DCC-GARCH"],  # Dynamic conditional
        "rank": [60],  # Spearman rank correlation
    },
    
    # Distribution
    "distribution": {
        "skewness": [60, 252],
        "kurtosis": [60, 252],
        "jarque_bera": [252],  # Normality test
    }
}
```

### 3. Machine Learning Metrics and Predictions

The pipeline now includes comprehensive ML model calibration and prediction generation for ML-based strategies:

```python
ML_METRICS = {
    # Model Predictions
    "predictions": {
        "rf_regressor_prediction": [],  # Random Forest predictions
        "gb_regressor_prediction": [],  # Gradient Boosting predictions
        "linear_prediction": [],  # Linear regression predictions
        "ridge_prediction": [],  # Ridge regression predictions
        "ml_ensemble_prediction": [],  # Ensemble average
    },
    
    # Confidence Scores
    "confidence": {
        "rf_regressor_confidence": [],  # Model confidence scores
        "gb_regressor_confidence": [],
        "ml_signal_strength": [],  # Signal strength (0-1)
    },
    
    # Trading Signals
    "signals": {
        "ml_signal": ["BUY", "SELL", "HOLD", "WAIT"],
        "ml_action": ["STRONG_BUY", "BUY", "HOLD", "SELL", "STRONG_SELL", "WAIT"],
        "ml_position_size": [],  # Recommended position size (0-0.2)
    },
    
    # Risk Assessment
    "risk": {
        "ml_risk_score": [],  # Risk score (0-1)
        "ml_expected_return": [],  # Expected next period return
    },
    
    # Model Performance (calculated on test set)
    "performance": {
        "ml_accuracy": [],  # Direction prediction accuracy
        "ml_precision": [],  # Precision score
        "ml_recall": [],  # Recall score
        "ml_f1": [],  # F1 score
        "ml_auc_roc": [],  # ROC AUC score
        "ml_r2": [],  # R-squared
        "ml_mse": [],  # Mean squared error
        "ml_mae": [],  # Mean absolute error
        "ml_hit_rate": [],  # Trading hit rate
        "ml_profit_factor": [],  # Profit factor
    },
    
    # Feature Importance
    "feature_importance": {
        "ml_feature_importance": {},  # Dict of feature importances
    }
}
```

#### ML Features Used

The ML models use the following engineered features:

```python
ML_FEATURES = {
    # Price-based Features
    "price_features": [
        "return_1d",  # 1-day return
        "return_5d",  # 5-day return
        "return_20d",  # 20-day return
        "close_to_sma20",  # Price relative to SMA20
        "close_to_sma50",  # Price relative to SMA50
    ],
    
    # Volume Features
    "volume_features": [
        "volume_ratio",  # Volume relative to 20-day average
    ],
    
    # Technical Indicators
    "technical_features": [
        "rsi", "macd", "macd_signal",
        "bb_upper", "bb_lower",
        "atr", "adx", "cci", "mfi",
        "obv_normalized"
    ],
    
    # Statistical Features
    "statistical_features": [
        "volatility_20",
        "skewness_20",
        "kurtosis_20",
        "volatility_regime"
    ]
}
```

#### Model Types

Four models are calibrated and ensembled:
1. **Random Forest Regressor** - Non-linear ensemble model
2. **Gradient Boosting Regressor** - Sequential boosting model
3. **Linear Regression** - Simple linear model
4. **Ridge Regression** - Regularized linear model

The ensemble prediction is a weighted average of all models, providing more robust predictions.

### 4. Market Microstructure Metrics

High-frequency trading metrics:

```python
MICROSTRUCTURE_METRICS = {
    "liquidity": {
        "amihud_illiquidity": [20],
        "roll_spread": [20],
        "effective_spread": [],
        "realized_spread": [],
    },
    
    "price_discovery": {
        "information_share": [],
        "common_factor_weight": [],
        "price_leadership": [],
    },
    
    "market_quality": {
        "quote_stability": [],
        "trade_informativeness": [],
        "adverse_selection": [],
    }
}
```

## Database Schema

### Metrics Storage Tables

```sql
CREATE SCHEMA IF NOT EXISTS derived;

-- Main metrics table (wide format for performance)
CREATE TABLE derived.metrics (
    scenario_id INTEGER REFERENCES scenarios.definitions(scenario_id),
    symbol VARCHAR(20) NOT NULL,
    timestamp TIMESTAMP NOT NULL,
    
    -- Technical Indicators (partial list)
    sma_20 DECIMAL(10,4),
    sma_50 DECIMAL(10,4),
    sma_200 DECIMAL(10,4),
    ema_12 DECIMAL(10,4),
    ema_26 DECIMAL(10,4),
    rsi_14 DECIMAL(5,2),
    macd DECIMAL(10,4),
    macd_signal DECIMAL(10,4),
    macd_histogram DECIMAL(10,4),
    bollinger_upper DECIMAL(10,4),
    bollinger_middle DECIMAL(10,4),
    bollinger_lower DECIMAL(10,4),
    atr_14 DECIMAL(10,4),
    obv BIGINT,
    
    -- Statistical Metrics
    returns_1d DECIMAL(8,6),
    returns_5d DECIMAL(8,6),
    returns_20d DECIMAL(8,6),
    volatility_20d DECIMAL(8,6),
    volatility_60d DECIMAL(8,6),
    correlation_spy_60d DECIMAL(5,4),
    var_95 DECIMAL(8,6),
    max_drawdown_252d DECIMAL(8,6),
    
    -- ML Features (stored as JSONB for flexibility)
    ml_features JSONB,
    
    -- Metadata
    calculation_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    PRIMARY KEY (scenario_id, symbol, timestamp)
);

-- Convert to TimescaleDB hypertable
SELECT create_hypertable('derived.metrics', 'timestamp');

-- Create indexes for common queries
CREATE INDEX idx_metrics_scenario_symbol ON derived.metrics(scenario_id, symbol);
CREATE INDEX idx_metrics_timestamp ON derived.metrics(timestamp DESC);
```

### Metric Definitions Table

```sql
CREATE TABLE derived.metric_definitions (
    metric_id SERIAL PRIMARY KEY,
    metric_name VARCHAR(100) NOT NULL UNIQUE,
    category VARCHAR(50),  -- 'technical', 'statistical', 'ml', 'microstructure'
    subcategory VARCHAR(50),
    parameters JSONB,
    formula TEXT,
    description TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### Calculation Status Table

```sql
CREATE TABLE derived.calculation_status (
    scenario_id INTEGER REFERENCES scenarios.definitions(scenario_id),
    calculation_type VARCHAR(50),  -- 'technical', 'statistical', 'ml', 'microstructure'
    status VARCHAR(20),  -- 'pending', 'running', 'completed', 'failed'
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    metrics_calculated INTEGER,
    error_message TEXT,
    PRIMARY KEY (scenario_id, calculation_type)
);
```

## Pipeline Workflow

### 1. Load Scenarios
```python
# Load active scenarios
scenarios = await load_active_scenarios()

for scenario in scenarios:
    # Check if metrics already calculated
    if await metrics_exist(scenario.id):
        logger.info(f"Metrics already calculated for scenario {scenario.name}")
        continue
```

### 2. Prepare Data
```python
# Load scenario data
data = await load_scenario_data(scenario)

# Prepare for calculation
prepared_data = prepare_data_for_metrics(data)
```

### 3. Calculate Metrics
```python
# Calculate technical indicators
technical_metrics = calculate_technical_indicators(
    prepared_data,
    indicators=TECHNICAL_INDICATORS_CONFIG
)

# Calculate statistical metrics
statistical_metrics = calculate_statistical_metrics(
    prepared_data,
    metrics=STATISTICAL_METRICS_CONFIG
)

# Calculate ML features
ml_features = calculate_ml_features(
    prepared_data,
    features=ML_FEATURES_CONFIG
)

# Combine all metrics
all_metrics = combine_metrics(
    technical_metrics,
    statistical_metrics,
    ml_features
)
```

### 4. Validate Metrics
```python
# Validate calculations
validation_results = validate_metrics(all_metrics)

if not validation_results.is_valid:
    logger.error(f"Validation failed: {validation_results.errors}")
    raise ValidationError(validation_results.errors)
```

### 5. Store Metrics
```python
# Batch insert metrics
await store_metrics_batch(
    scenario_id=scenario.id,
    metrics=all_metrics,
    batch_size=10000
)

# Update calculation status
await update_calculation_status(
    scenario_id=scenario.id,
    status="completed",
    metrics_calculated=len(all_metrics)
)
```

## CLI Usage

### Basic Commands

```bash
# Calculate metrics for all scenarios
python -m src.pipelines.metrics_pipeline.main --scenario all

# Calculate for specific scenario
python -m src.pipelines.metrics_pipeline.main --scenario-id 42

# Calculate only technical indicators
python -m src.pipelines.metrics_pipeline.main --type technical --scenario all

# Calculate with parallel processing
python -m src.pipelines.metrics_pipeline.main --scenario all --parallel --workers 8
```

### Advanced Options

```bash
# Recalculate existing metrics
python -m src.pipelines.metrics_pipeline.main \
    --scenario all \
    --force-recalculate

# Calculate for specific symbols
python -m src.pipelines.metrics_pipeline.main \
    --scenario all \
    --symbols SPY,QQQ,IWM

# Use specific date range
python -m src.pipelines.metrics_pipeline.main \
    --scenario all \
    --start-date 2020-01-01 \
    --end-date 2024-12-31

# Dry run (no database writes)
python -m src.pipelines.metrics_pipeline.main \
    --scenario all \
    --dry-run
```

## Configuration

### Pipeline Configuration (config/metrics_pipeline.yaml)

```yaml
metrics_pipeline:
  # Metric categories to calculate
  categories:
    technical:
      enabled: true
      indicators:
        trend: ["sma", "ema", "macd", "adx"]
        momentum: ["rsi", "stochastic", "cci"]
        volatility: ["bollinger", "atr", "keltner"]
        volume: ["obv", "mfi", "vwap"]
    
    statistical:
      enabled: true
      metrics:
        returns: [1, 5, 20, 60]
        volatility: [20, 60, 252]
        risk: ["var_95", "cvar_95", "max_drawdown"]
    
    ml_features:
      enabled: true
      feature_sets:
        - price_based
        - momentum_based
        - pattern_based
    
    microstructure:
      enabled: false  # Requires tick data
  
  # Calculation settings
  calculation:
    batch_size: 10000
    parallel_workers: 8
    use_gpu: false  # For ML features
    cache_intermediate: true
  
  # Validation settings
  validation:
    check_nans: true
    check_infinites: true
    check_bounds: true
    statistical_tests: true
  
  # Storage settings
  storage:
    compression: true
    partition_by_month: true
    retain_days: 730  # 2 years
```

## Performance Optimization

### 1. Vectorized Calculations
```python
# Use NumPy/Pandas vectorized operations
def calculate_rsi_vectorized(prices, period=14):
    delta = prices.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))
```

### 2. Parallel Processing
```python
# Process symbols in parallel
from concurrent.futures import ProcessPoolExecutor

def process_symbol(symbol_data):
    return calculate_all_metrics(symbol_data)

with ProcessPoolExecutor(max_workers=8) as executor:
    results = executor.map(process_symbol, symbol_data_chunks)
```

### 3. Caching Strategy
```python
# Cache expensive calculations
@lru_cache(maxsize=1000)
def calculate_correlation_matrix(returns_tuple):
    returns = np.array(returns_tuple)
    return np.corrcoef(returns)
```

### 4. Batch Database Operations
```python
# Batch insert metrics
async def store_metrics_batch(metrics_df, batch_size=10000):
    for i in range(0, len(metrics_df), batch_size):
        batch = metrics_df.iloc[i:i+batch_size]
        await bulk_insert_metrics(batch)
```

## Resource Requirements

```yaml
# Typical resource usage per scenario
memory:
  technical_indicators: 4GB
  statistical_metrics: 6GB
  ml_features: 8GB
  microstructure: 10GB

processing_time:
  technical_indicators: 10 minutes
  statistical_metrics: 15 minutes
  ml_features: 30 minutes
  microstructure: 45 minutes

storage_per_scenario:
  technical_indicators: 500MB
  statistical_metrics: 300MB
  ml_features: 1GB
  microstructure: 2GB
```

## Monitoring and Validation

### Quality Checks

```python
VALIDATION_RULES = {
    "technical": {
        "rsi": lambda x: 0 <= x <= 100,
        "correlation": lambda x: -1 <= x <= 1,
        "returns": lambda x: -1 < x < 10,  # Daily returns
    },
    "statistical": {
        "volatility": lambda x: 0 < x < 2,  # Annualized
        "var": lambda x: x < 0,  # VaR is negative
        "max_drawdown": lambda x: -1 <= x <= 0,
    }
}
```

### Monitoring Metrics

- Calculation time per scenario
- Memory usage during calculation
- Number of NaN/Inf values detected
- Validation failure rate
- Storage space used

## API Endpoints

```python
# FastAPI routes
@router.get("/metrics/scenarios/{scenario_id}")
async def get_scenario_metrics(
    scenario_id: int,
    symbol: Optional[str] = None,
    metric_type: Optional[str] = None
) -> pd.DataFrame:
    """Get calculated metrics for a scenario"""

@router.post("/metrics/calculate")
async def trigger_calculation(
    scenario_id: int,
    metric_types: List[str]
) -> CalculationResult:
    """Trigger metric calculation for a scenario"""

@router.get("/metrics/status/{scenario_id}")
async def get_calculation_status(
    scenario_id: int
) -> CalculationStatus:
    """Get calculation status for a scenario"""

@router.get("/metrics/definitions")
async def list_metric_definitions(
    category: Optional[str] = None
) -> List[MetricDefinition]:
    """List available metric definitions"""
```

## Best Practices

1. **Incremental Calculation**: Only calculate new metrics when scenarios update
2. **Validation First**: Always validate metrics before storing
3. **Documentation**: Document all custom indicators and features
4. **Version Control**: Version metric definitions for reproducibility
5. **Error Handling**: Gracefully handle calculation failures
6. **Resource Management**: Monitor memory usage during calculation

## Troubleshooting

### Common Issues

1. **Out of memory during calculation**
   - Reduce batch size
   - Process fewer symbols at once
   - Use disk-based caching

2. **Slow calculation performance**
   - Enable parallel processing
   - Use vectorized operations
   - Cache intermediate results

3. **Validation failures**
   - Check for data quality issues
   - Review calculation logic
   - Verify input data ranges

4. **Database storage errors**
   - Check disk space
   - Verify database connectivity
   - Review batch size settings

## Integration with Pipeline Architecture

### Pipeline Flow
```
Stage 1: Data Pipeline (7:00 PM)
  ↓
Stage 2: Scenarios Pipeline (7:30 PM)
  ↓
Stage 3: Metrics Pipeline (8:00 PM) ← Next stage to implement
  ↓
Stage 4: Assessment Pipeline (Backtests strategies)
```

### Input Sources
- **Scenarios Pipeline**: Loads 131 scenarios from `data/scenarios/`
  - Historical events (Bull, Crisis, Full Cycles)
  - Stochastic scenarios (Monte Carlo, Bootstrap)
  - Stress test scenarios
- **Market Data**: Direct access to `market_data.ohlcv` for calculations

### Output for Assessment Pipeline
- Pre-calculated metrics for all scenarios
- Eliminates need for indicator calculation during backtesting
- Ensures consistent metric values across all strategy tests

## Current Implementation Summary

### What's Working Now
1. **Automated Daily Execution**: Runs at 8:00 PM after scenarios complete
2. **Complete Metrics**: 120+ indicators/metrics calculated for maximum flexibility
3. **Comprehensive Storage**: ~50MB per scenario with Parquet compression
4. **Parallel Processing**: 8-core parallel execution
5. **Total Storage**: ~7GB for all 131 scenarios (acceptable for comprehensive coverage)
6. **Execution Time**: ~5.5 hours for all 131 scenarios on 8-core machine

### Daily Pipeline Flow
```
7:00 PM → Data Pipeline (30 min)
   ↓
7:30 PM → Scenarios Pipeline (30 min)
   ↓
8:00 PM → Metrics Pipeline (5.5 hours)
   ↓
1:30 AM → Complete (ready for next day's backtesting)
```

### Storage Structure
```
data/metrics/
├── scenario_1_metrics.parquet      # ~50MB each
├── scenario_2_metrics.parquet      # 120+ metrics per symbol
├── ...
├── scenario_131_metrics.parquet    # Total: ~7GB
└── metrics_pipeline_summary.json
```

**Why Store Everything?**
- **Flexibility**: Any strategy can use any metric without recalculation
- **Consistency**: All strategies use identical metric values
- **Performance**: No calculation overhead during backtesting
- **Storage is Cheap**: 7GB is reasonable for comprehensive coverage
- **Daily Overwrite**: Storage doesn't grow over time

## Future Enhancements

### Phase 2 Implementation (Planned)
- **ML Features Calculator**: 150+ feature engineering metrics
- **Event Metrics**: Earnings, economic events, corporate actions
- **Time-Based Metrics**: Intraday patterns, session metrics
- **Microstructure Metrics**: Bid-ask spread, order flow

### Performance Optimizations
- **GPU Acceleration**: Use RAPIDS for faster calculations
- **Incremental Updates**: Only calculate new data points
- **Distributed Processing**: Scale across multiple machines
- **Real-time Streaming**: Calculate metrics as data arrives

### Additional Features
- **Custom Metrics UI**: Web interface for defining custom metrics
- **ML Model Integration**: Pre-compute ML model predictions
- **Cross-sectional Metrics**: Calculate relative metrics across symbols
- **Metric Versioning**: Track changes in calculation methods